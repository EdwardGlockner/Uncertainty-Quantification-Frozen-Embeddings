This job can be monitored from: https://job.c3se.chalmers.se/alvis/3190928
Lmod has detected the following error: The following module(s) are unknown:
"ftfy"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore_cache load "ftfy"

Also make sure that all modulefiles written in TCL start with the string
#%Module



/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/ds/vocabs/coco_vocab.pkl
creating index...
index created!
Loading COCO Caption: n_images 113287 n_captions 566435...
loading annotations into memory...
Done (t=0.25s)
creating index...
index created!
Loading COCO Caption: n_images 1000 n_captions 5000...
loading annotations into memory...
Done (t=0.23s)
creating index...
index created!
Loading COCO Caption: n_images 5000 n_captions 25000...
Loading checkpoint from ../ckpt/BBB_woKL_Net_best.pth...
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:05<06:38,  5.10s/it]  3%|▎         | 2/79 [00:05<03:07,  2.44s/it]  4%|▍         | 3/79 [00:06<02:07,  1.67s/it]  5%|▌         | 4/79 [00:07<01:48,  1.44s/it]  6%|▋         | 5/79 [00:08<01:22,  1.12s/it]  8%|▊         | 6/79 [00:08<01:07,  1.08it/s]  9%|▉         | 7/79 [00:09<01:16,  1.07s/it] 10%|█         | 8/79 [00:10<01:04,  1.10it/s] 11%|█▏        | 9/79 [00:11<00:55,  1.26it/s] 13%|█▎        | 10/79 [00:11<00:49,  1.39it/s] 14%|█▍        | 11/79 [00:12<00:45,  1.51it/s] 15%|█▌        | 12/79 [00:13<01:05,  1.03it/s] 16%|█▋        | 13/79 [00:14<00:55,  1.18it/s] 18%|█▊        | 14/79 [00:14<00:48,  1.35it/s] 19%|█▉        | 15/79 [00:15<00:42,  1.52it/s] 20%|██        | 16/79 [00:15<00:37,  1.68it/s] 22%|██▏       | 17/79 [00:16<00:34,  1.82it/s] 23%|██▎       | 18/79 [00:18<01:00,  1.01it/s] 24%|██▍       | 19/79 [00:18<00:49,  1.21it/s] 25%|██▌       | 20/79 [00:19<00:42,  1.40it/s] 27%|██▋       | 21/79 [00:19<00:36,  1.58it/s] 28%|██▊       | 22/79 [00:20<00:32,  1.73it/s] 29%|██▉       | 23/79 [00:20<00:30,  1.86it/s] 30%|███       | 24/79 [00:20<00:28,  1.95it/s] 32%|███▏      | 25/79 [00:21<00:26,  2.03it/s] 33%|███▎      | 26/79 [00:24<01:01,  1.16s/it] 34%|███▍      | 27/79 [00:24<00:49,  1.06it/s] 35%|███▌      | 28/79 [00:25<00:40,  1.26it/s] 37%|███▋      | 29/79 [00:25<00:34,  1.45it/s] 38%|███▊      | 30/79 [00:25<00:30,  1.62it/s] 39%|███▉      | 31/79 [00:26<00:27,  1.77it/s] 41%|████      | 32/79 [00:26<00:24,  1.89it/s] 42%|████▏     | 33/79 [00:27<00:23,  1.97it/s] 43%|████▎     | 34/79 [00:27<00:21,  2.05it/s] 44%|████▍     | 35/79 [00:31<01:01,  1.41s/it] 46%|████▌     | 36/79 [00:31<00:48,  1.12s/it] 47%|████▋     | 37/79 [00:32<00:38,  1.09it/s] 48%|████▊     | 38/79 [00:32<00:31,  1.29it/s] 49%|████▉     | 39/79 [00:33<00:27,  1.47it/s] 51%|█████     | 40/79 [00:33<00:23,  1.64it/s] 52%|█████▏    | 41/79 [00:33<00:21,  1.79it/s] 53%|█████▎    | 42/79 [00:34<00:19,  1.91it/s] 54%|█████▍    | 43/79 [00:34<00:18,  1.98it/s] 56%|█████▌    | 44/79 [00:35<00:17,  2.06it/s] 57%|█████▋    | 45/79 [00:35<00:16,  2.11it/s] 58%|█████▊    | 46/79 [00:36<00:15,  2.15it/s] 59%|█████▉    | 47/79 [00:40<00:52,  1.65s/it] 61%|██████    | 48/79 [00:41<00:39,  1.29s/it] 62%|██████▏   | 49/79 [00:41<00:30,  1.03s/it] 63%|██████▎   | 50/79 [00:41<00:24,  1.17it/s] 65%|██████▍   | 51/79 [00:42<00:20,  1.37it/s] 66%|██████▌   | 52/79 [00:42<00:17,  1.54it/s] 67%|██████▋   | 53/79 [00:43<00:15,  1.70it/s] 68%|██████▊   | 54/79 [00:43<00:13,  1.84it/s] 70%|██████▉   | 55/79 [00:44<00:12,  1.94it/s] 71%|███████   | 56/79 [00:44<00:11,  2.01it/s] 72%|███████▏  | 57/79 [00:45<00:10,  2.08it/s] 73%|███████▎  | 58/79 [00:45<00:09,  2.13it/s] 75%|███████▍  | 59/79 [00:45<00:09,  2.17it/s] 76%|███████▌  | 60/79 [00:46<00:08,  2.19it/s] 77%|███████▋  | 61/79 [00:51<00:35,  2.00s/it] 78%|███████▊  | 62/79 [00:52<00:26,  1.53s/it] 80%|███████▉  | 63/79 [00:52<00:19,  1.21s/it] 81%|████████  | 64/79 [00:53<00:14,  1.02it/s] 82%|████████▏ | 65/79 [00:53<00:11,  1.22it/s] 84%|████████▎ | 66/79 [00:54<00:09,  1.41it/s] 85%|████████▍ | 67/79 [00:54<00:07,  1.59it/s] 86%|████████▌ | 68/79 [00:55<00:06,  1.75it/s] 87%|████████▋ | 69/79 [00:55<00:05,  1.87it/s] 89%|████████▊ | 70/79 [00:55<00:04,  1.96it/s] 90%|████████▉ | 71/79 [00:56<00:03,  2.04it/s] 91%|█████████ | 72/79 [00:56<00:03,  2.10it/s] 92%|█████████▏| 73/79 [00:57<00:02,  2.15it/s] 94%|█████████▎| 74/79 [00:57<00:02,  2.17it/s] 95%|█████████▍| 75/79 [00:58<00:01,  2.18it/s] 96%|█████████▌| 76/79 [00:58<00:01,  2.20it/s] 97%|█████████▋| 77/79 [00:59<00:00,  2.22it/s] 99%|█████████▊| 78/79 [00:59<00:00,  2.23it/s]100%|██████████| 79/79 [00:59<00:00,  2.90it/s]100%|██████████| 79/79 [00:59<00:00,  1.32it/s]
Query: tensor([[-0.6628,  1.4950, -0.0807,  ...,  4.2856,  0.0485,  0.0095],
        [-0.6628,  1.4950, -0.0807,  ...,  4.2856,  0.0485,  0.0095],
        [-0.6628,  1.4950, -0.0807,  ...,  4.2856,  0.0485,  0.0095],
        ...,
        [-0.5209,  1.4992, -0.1342,  ...,  4.4089, -0.1064, -0.1323],
        [-0.5209,  1.4992, -0.1342,  ...,  4.4089, -0.1064, -0.1323],
        [-0.5209,  1.4992, -0.1342,  ...,  4.4089, -0.1064, -0.1323]],
       device='cuda:0')
Gallery: tensor([[ 0.0014,  0.0020, -0.0087,  ...,  0.0261, -0.0048, -0.0231],
        [ 0.0014,  0.0020, -0.0087,  ...,  0.0261, -0.0048, -0.0231],
        [ 0.0014,  0.0020, -0.0087,  ...,  0.0261, -0.0048, -0.0231],
        ...,
        [ 0.0019,  0.0019, -0.0086,  ...,  0.0262, -0.0049, -0.0237],
        [ 0.0019,  0.0019, -0.0086,  ...,  0.0262, -0.0049, -0.0237],
        [ 0.0019,  0.0019, -0.0086,  ...,  0.0262, -0.0049, -0.0237]],
       device='cuda:0')
Pred Ranks: [[1295]
 [1295]
 [1295]
 ...
 [1295]
 [1295]
 [1295]]
Recall@1 for each bin: [0.000999000999000999, 0.001001001001001001, 0.001001001001001001, 0.001001001001001001, 0.001002004008016032]
/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/ds/vocabs/coco_vocab.pkl
creating index...
index created!
Loading COCO Caption: n_images 113287 n_captions 566435...
loading annotations into memory...
Done (t=0.25s)
creating index...
index created!
Loading COCO Caption: n_images 1000 n_captions 5000...
loading annotations into memory...
Done (t=0.22s)
creating index...
index created!
Loading COCO Caption: n_images 5000 n_captions 25000...
Loading Flickr Caption: n_captions 148915...
Loading Flickr Caption: n_captions 5000...
Loading Flickr Caption: n_captions 5000...
Loading checkpoint from ../ckpt/BBB_woKL_Net_best.pth...
Evaluating uncertainties on coco (in-distribution)
Estimating uncertainties on IOD:   0%|          | 0/79 [00:00<?, ?batch/s]Estimating uncertainties on IOD:   0%|          | 0/79 [00:05<?, ?batch/s]
Traceback (most recent call last):
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 322, in <module>
    main()
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 318, in main
    iod_ood = compare_iod_vs_ood(ckpt_path=model)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 295, in compare_iod_vs_ood
    iod_image_uncertainty, iod_text_uncertainty = estimate_uncertainty_variances(iod_valid_loader, "IOD")
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 278, in estimate_uncertainty_variances
    (_, _, _, i_v), (_, _, _, t_v) = multi_fwpass_ProbVLM(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/utils.py", line 186, in multi_fwpass_ProbVLM
    (img_mu, img_1alpha, img_beta), (txt_mu, txt_1alpha, txt_beta) = BayesCap_Net(xfI, xfT)
                                                                     ^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/networks.py", line 140, in forward
    img_mu, img_1alpha, img_beta = self.img_BayesCap(i_features)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/networks.py", line 88, in forward
    x_intr = self.mod(x)
             ^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/UQ_venv/lib/python3.11/site-packages/torchbnn/modules/linear.py", line 98, in forward
    return F.linear(input, weight, bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)
