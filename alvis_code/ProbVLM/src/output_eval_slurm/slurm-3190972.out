This job can be monitored from: https://grafana.c3se.chalmers.se/d/gpu-job/gpu-job?var-jobid=3190972&from=1732547941000
Lmod has detected the following error: The following module(s) are unknown:
"ftfy"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore_cache load "ftfy"

Also make sure that all modulefiles written in TCL start with the string
#%Module



/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/ds/vocabs/coco_vocab.pkl
creating index...
index created!
Loading COCO Caption: n_images 113287 n_captions 566435...
loading annotations into memory...
Done (t=0.25s)
creating index...
index created!
Loading COCO Caption: n_images 1000 n_captions 5000...
loading annotations into memory...
Done (t=0.23s)
creating index...
index created!
Loading COCO Caption: n_images 5000 n_captions 25000...
Loading checkpoint from ../ckpt/BBB_woKL_Net_best.pth...
  0%|          | 0/79 [00:00<?, ?it/s]  1%|▏         | 1/79 [00:05<06:36,  5.08s/it]  3%|▎         | 2/79 [00:06<03:28,  2.70s/it]  4%|▍         | 3/79 [00:06<02:11,  1.73s/it]  5%|▌         | 4/79 [00:07<01:49,  1.46s/it]  6%|▋         | 5/79 [00:08<01:24,  1.14s/it]  8%|▊         | 6/79 [00:08<01:08,  1.07it/s]  9%|▉         | 7/79 [00:10<01:16,  1.06s/it] 10%|█         | 8/79 [00:10<01:04,  1.11it/s] 11%|█▏        | 9/79 [00:11<00:55,  1.27it/s] 13%|█▎        | 10/79 [00:11<00:49,  1.39it/s] 14%|█▍        | 11/79 [00:12<00:45,  1.49it/s] 15%|█▌        | 12/79 [00:14<01:04,  1.03it/s] 16%|█▋        | 13/79 [00:14<00:53,  1.23it/s] 18%|█▊        | 14/79 [00:14<00:45,  1.41it/s] 19%|█▉        | 15/79 [00:15<00:40,  1.57it/s] 20%|██        | 16/79 [00:15<00:36,  1.72it/s] 22%|██▏       | 17/79 [00:16<00:33,  1.84it/s] 23%|██▎       | 18/79 [00:18<01:00,  1.01it/s] 24%|██▍       | 19/79 [00:18<00:49,  1.21it/s] 25%|██▌       | 20/79 [00:19<00:42,  1.39it/s] 27%|██▋       | 21/79 [00:19<00:37,  1.56it/s] 28%|██▊       | 22/79 [00:20<00:33,  1.71it/s] 29%|██▉       | 23/79 [00:20<00:30,  1.83it/s] 30%|███       | 24/79 [00:21<00:28,  1.91it/s] 32%|███▏      | 25/79 [00:21<00:27,  1.99it/s] 33%|███▎      | 26/79 [00:24<01:01,  1.16s/it] 34%|███▍      | 27/79 [00:24<00:49,  1.06it/s] 35%|███▌      | 28/79 [00:25<00:40,  1.26it/s] 37%|███▋      | 29/79 [00:25<00:34,  1.44it/s] 38%|███▊      | 30/79 [00:26<00:30,  1.60it/s] 39%|███▉      | 31/79 [00:26<00:27,  1.75it/s] 41%|████      | 32/79 [00:26<00:24,  1.88it/s] 42%|████▏     | 33/79 [00:27<00:23,  1.98it/s] 43%|████▎     | 34/79 [00:27<00:22,  2.05it/s] 44%|████▍     | 35/79 [00:31<01:00,  1.38s/it] 46%|████▌     | 36/79 [00:31<00:47,  1.10s/it] 47%|████▋     | 37/79 [00:32<00:37,  1.11it/s] 48%|████▊     | 38/79 [00:32<00:31,  1.31it/s] 49%|████▉     | 39/79 [00:33<00:26,  1.49it/s] 51%|█████     | 40/79 [00:33<00:23,  1.66it/s] 52%|█████▏    | 41/79 [00:33<00:21,  1.81it/s] 53%|█████▎    | 42/79 [00:34<00:19,  1.93it/s] 54%|█████▍    | 43/79 [00:34<00:17,  2.00it/s] 56%|█████▌    | 44/79 [00:35<00:16,  2.08it/s] 57%|█████▋    | 45/79 [00:35<00:15,  2.13it/s] 58%|█████▊    | 46/79 [00:36<00:15,  2.17it/s] 59%|█████▉    | 47/79 [00:40<00:51,  1.62s/it] 61%|██████    | 48/79 [00:40<00:39,  1.27s/it] 62%|██████▏   | 49/79 [00:41<00:30,  1.02s/it] 63%|██████▎   | 50/79 [00:41<00:24,  1.18it/s] 65%|██████▍   | 51/79 [00:42<00:20,  1.38it/s] 66%|██████▌   | 52/79 [00:42<00:17,  1.55it/s] 67%|██████▋   | 53/79 [00:43<00:15,  1.72it/s] 68%|██████▊   | 54/79 [00:43<00:13,  1.85it/s] 70%|██████▉   | 55/79 [00:44<00:12,  1.96it/s] 71%|███████   | 56/79 [00:44<00:11,  2.04it/s] 72%|███████▏  | 57/79 [00:44<00:10,  2.09it/s] 73%|███████▎  | 58/79 [00:45<00:09,  2.14it/s] 75%|███████▍  | 59/79 [00:45<00:09,  2.18it/s] 76%|███████▌  | 60/79 [00:46<00:08,  2.21it/s] 77%|███████▋  | 61/79 [00:51<00:35,  1.96s/it] 78%|███████▊  | 62/79 [00:52<00:25,  1.51s/it] 80%|███████▉  | 63/79 [00:52<00:18,  1.19s/it] 81%|████████  | 64/79 [00:53<00:14,  1.04it/s] 82%|████████▏ | 65/79 [00:53<00:11,  1.24it/s] 84%|████████▎ | 66/79 [00:53<00:09,  1.43it/s] 85%|████████▍ | 67/79 [00:54<00:07,  1.61it/s] 86%|████████▌ | 68/79 [00:54<00:06,  1.76it/s] 87%|████████▋ | 69/79 [00:55<00:05,  1.89it/s] 89%|████████▊ | 70/79 [00:55<00:04,  1.99it/s] 90%|████████▉ | 71/79 [00:56<00:03,  2.05it/s] 91%|█████████ | 72/79 [00:56<00:03,  2.12it/s] 92%|█████████▏| 73/79 [00:57<00:02,  2.16it/s] 94%|█████████▎| 74/79 [00:57<00:02,  2.19it/s] 95%|█████████▍| 75/79 [00:57<00:01,  2.20it/s] 96%|█████████▌| 76/79 [00:58<00:01,  2.22it/s] 97%|█████████▋| 77/79 [00:58<00:00,  2.23it/s] 99%|█████████▊| 78/79 [00:59<00:00,  2.24it/s]100%|██████████| 79/79 [00:59<00:00,  2.91it/s]100%|██████████| 79/79 [00:59<00:00,  1.33it/s]
Query: tensor([[-0.5208,  1.4972, -0.1109,  ...,  4.4054, -0.0959, -0.1269],
        [-0.5208,  1.4972, -0.1109,  ...,  4.4054, -0.0959, -0.1269],
        [-0.5208,  1.4972, -0.1109,  ...,  4.4054, -0.0959, -0.1269],
        ...,
        [-0.5263,  1.4976, -0.1236,  ...,  4.4260, -0.1130, -0.1265],
        [-0.5263,  1.4976, -0.1236,  ...,  4.4260, -0.1130, -0.1265],
        [-0.5263,  1.4976, -0.1236,  ...,  4.4260, -0.1130, -0.1265]],
       device='cuda:0')
Gallery: tensor([[ 0.0016,  0.0017, -0.0086,  ...,  0.0262, -0.0048, -0.0234],
        [ 0.0016,  0.0017, -0.0086,  ...,  0.0262, -0.0048, -0.0234],
        [ 0.0016,  0.0017, -0.0086,  ...,  0.0262, -0.0048, -0.0234],
        ...,
        [ 0.0017,  0.0019, -0.0086,  ...,  0.0263, -0.0049, -0.0235],
        [ 0.0017,  0.0019, -0.0086,  ...,  0.0263, -0.0049, -0.0235],
        [ 0.0017,  0.0019, -0.0086,  ...,  0.0263, -0.0049, -0.0235]],
       device='cuda:0')
Pred Ranks: [[452]
 [452]
 [452]
 ...
 [452]
 [452]
 [452]]
Recall@1 for each bin: [0.0, 0.0, 0.002002002002002002, 0.01001001001001001, 0.9789579158316634]
/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/ds/vocabs/coco_vocab.pkl
creating index...
index created!
Loading COCO Caption: n_images 113287 n_captions 566435...
loading annotations into memory...
Done (t=0.23s)
creating index...
index created!
Loading COCO Caption: n_images 1000 n_captions 5000...
loading annotations into memory...
Done (t=0.22s)
creating index...
index created!
Loading COCO Caption: n_images 5000 n_captions 25000...
Loading Flickr Caption: n_captions 148915...
Loading Flickr Caption: n_captions 5000...
Loading Flickr Caption: n_captions 5000...
Loading checkpoint from ../ckpt/BBB_woKL_Net_best.pth...
Evaluating uncertainties on coco (in-distribution)
Estimating uncertainties on IOD:   0%|          | 0/79 [00:00<?, ?batch/s]Estimating uncertainties on IOD:   1%|▏         | 1/79 [00:04<05:41,  4.38s/batch]Estimating uncertainties on IOD:   3%|▎         | 2/79 [00:04<02:29,  1.94s/batch]Estimating uncertainties on IOD:   4%|▍         | 3/79 [00:04<01:26,  1.14s/batch]Estimating uncertainties on IOD:   5%|▌         | 4/79 [00:05<00:58,  1.28batch/s]Estimating uncertainties on IOD:   6%|▋         | 5/79 [00:05<00:41,  1.78batch/s]Estimating uncertainties on IOD:   8%|▊         | 6/79 [00:05<00:31,  2.32batch/s]Estimating uncertainties on IOD:   9%|▉         | 7/79 [00:05<00:24,  2.88batch/s]Estimating uncertainties on IOD:  10%|█         | 8/79 [00:05<00:20,  3.42batch/s]Estimating uncertainties on IOD:  11%|█▏        | 9/79 [00:05<00:17,  3.90batch/s]Estimating uncertainties on IOD:  13%|█▎        | 10/79 [00:06<00:15,  4.31batch/s]Estimating uncertainties on IOD:  14%|█▍        | 11/79 [00:06<00:14,  4.69batch/s]Estimating uncertainties on IOD:  15%|█▌        | 12/79 [00:06<00:13,  4.97batch/s]Estimating uncertainties on IOD:  16%|█▋        | 13/79 [00:06<00:12,  5.19batch/s]Estimating uncertainties on IOD:  18%|█▊        | 14/79 [00:06<00:12,  5.35batch/s]Estimating uncertainties on IOD:  19%|█▉        | 15/79 [00:07<00:19,  3.33batch/s]Estimating uncertainties on IOD:  20%|██        | 16/79 [00:07<00:16,  3.84batch/s]Estimating uncertainties on IOD:  22%|██▏       | 17/79 [00:07<00:14,  4.27batch/s]Estimating uncertainties on IOD:  23%|██▎       | 18/79 [00:07<00:13,  4.68batch/s]Estimating uncertainties on IOD:  24%|██▍       | 19/79 [00:08<00:12,  5.00batch/s]Estimating uncertainties on IOD:  25%|██▌       | 20/79 [00:08<00:11,  5.25batch/s]Estimating uncertainties on IOD:  27%|██▋       | 21/79 [00:08<00:10,  5.43batch/s]Estimating uncertainties on IOD:  28%|██▊       | 22/79 [00:08<00:10,  5.57batch/s]Estimating uncertainties on IOD:  29%|██▉       | 23/79 [00:08<00:09,  5.68batch/s]Estimating uncertainties on IOD:  30%|███       | 24/79 [00:08<00:09,  5.76batch/s]Estimating uncertainties on IOD:  32%|███▏      | 25/79 [00:09<00:09,  5.81batch/s]Estimating uncertainties on IOD:  33%|███▎      | 26/79 [00:09<00:09,  5.85batch/s]Estimating uncertainties on IOD:  34%|███▍      | 27/79 [00:09<00:08,  5.87batch/s]Estimating uncertainties on IOD:  35%|███▌      | 28/79 [00:09<00:08,  5.89batch/s]Estimating uncertainties on IOD:  37%|███▋      | 29/79 [00:09<00:08,  5.90batch/s]Estimating uncertainties on IOD:  38%|███▊      | 30/79 [00:09<00:08,  5.91batch/s]Estimating uncertainties on IOD:  39%|███▉      | 31/79 [00:10<00:08,  5.91batch/s]Estimating uncertainties on IOD:  41%|████      | 32/79 [00:10<00:07,  5.91batch/s]Estimating uncertainties on IOD:  42%|████▏     | 33/79 [00:10<00:07,  5.91batch/s]Estimating uncertainties on IOD:  43%|████▎     | 34/79 [00:10<00:07,  5.82batch/s]Estimating uncertainties on IOD:  44%|████▍     | 35/79 [00:10<00:07,  5.85batch/s]Estimating uncertainties on IOD:  46%|████▌     | 36/79 [00:10<00:07,  5.88batch/s]Estimating uncertainties on IOD:  47%|████▋     | 37/79 [00:11<00:07,  5.88batch/s]Estimating uncertainties on IOD:  48%|████▊     | 38/79 [00:11<00:06,  5.87batch/s]Estimating uncertainties on IOD:  49%|████▉     | 39/79 [00:11<00:06,  5.84batch/s]Estimating uncertainties on IOD:  51%|█████     | 40/79 [00:11<00:06,  5.85batch/s]Estimating uncertainties on IOD:  52%|█████▏    | 41/79 [00:11<00:06,  5.84batch/s]Estimating uncertainties on IOD:  53%|█████▎    | 42/79 [00:11<00:06,  5.84batch/s]Estimating uncertainties on IOD:  54%|█████▍    | 43/79 [00:12<00:06,  5.83batch/s]Estimating uncertainties on IOD:  56%|█████▌    | 44/79 [00:12<00:06,  5.83batch/s]Estimating uncertainties on IOD:  57%|█████▋    | 45/79 [00:12<00:05,  5.83batch/s]Estimating uncertainties on IOD:  58%|█████▊    | 46/79 [00:12<00:05,  5.82batch/s]Estimating uncertainties on IOD:  59%|█████▉    | 47/79 [00:12<00:05,  5.84batch/s]Estimating uncertainties on IOD:  61%|██████    | 48/79 [00:12<00:05,  5.85batch/s]Estimating uncertainties on IOD:  62%|██████▏   | 49/79 [00:13<00:05,  5.83batch/s]Estimating uncertainties on IOD:  63%|██████▎   | 50/79 [00:13<00:04,  5.85batch/s]Estimating uncertainties on IOD:  65%|██████▍   | 51/79 [00:13<00:04,  5.86batch/s]Estimating uncertainties on IOD:  66%|██████▌   | 52/79 [00:13<00:04,  5.85batch/s]Estimating uncertainties on IOD:  67%|██████▋   | 53/79 [00:13<00:04,  5.83batch/s]Estimating uncertainties on IOD:  68%|██████▊   | 54/79 [00:13<00:04,  5.81batch/s]Estimating uncertainties on IOD:  70%|██████▉   | 55/79 [00:14<00:04,  5.71batch/s]Estimating uncertainties on IOD:  71%|███████   | 56/79 [00:14<00:04,  5.72batch/s]Estimating uncertainties on IOD:  72%|███████▏  | 57/79 [00:14<00:03,  5.73batch/s]Estimating uncertainties on IOD:  73%|███████▎  | 58/79 [00:14<00:03,  5.74batch/s]Estimating uncertainties on IOD:  75%|███████▍  | 59/79 [00:14<00:03,  5.74batch/s]Estimating uncertainties on IOD:  76%|███████▌  | 60/79 [00:15<00:03,  5.76batch/s]Estimating uncertainties on IOD:  77%|███████▋  | 61/79 [00:15<00:03,  5.77batch/s]Estimating uncertainties on IOD:  78%|███████▊  | 62/79 [00:15<00:02,  5.71batch/s]Estimating uncertainties on IOD:  78%|███████▊  | 62/79 [00:15<00:04,  3.93batch/s]
Traceback (most recent call last):
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 340, in <module>
    main()
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 336, in main
    iod_ood = compare_iod_vs_ood(ckpt_path=model)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 313, in compare_iod_vs_ood
    iod_image_uncertainty, iod_text_uncertainty = estimate_uncertainty_variances(iod_valid_loader, "IOD", Net, CLIP_Net, n_fw=n_fw)
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 293, in estimate_uncertainty_variances
    xfI, xfT = CLIP_Net(xI, xT)
               ^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/clip/model.py", line 379, in forward
    image_features = self.encode_image(image, is_weights)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/clip/model.py", line 358, in encode_image
    return self.visual(image.type(self.dtype), is_weights)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/clip/model.py", line 244, in forward
    x = self.transformer(x)
        ^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/clip/model.py", line 206, in forward
    x, weights = block(x)
                 ^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/clip/model.py", line 191, in forward
    x = x + self.mlp(self.ln_2(x))
            ^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/clip/model.py", line 164, in forward
    return x * torch.sigmoid(1.702 * x)
               ^^^^^^^^^^^^^^^^^^^^^^^^
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 44.67 GiB of which 10.69 MiB is free. Including non-PyTorch memory, this process has 44.63 GiB memory in use. Of the allocated memory 44.24 GiB is allocated by PyTorch, and 74.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
