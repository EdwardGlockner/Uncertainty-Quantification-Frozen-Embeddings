This job can be monitored from: https://grafana.c3se.chalmers.se/d/gpu-job/gpu-job?var-jobid=3191252&from=1732550198000
Lmod has detected the following error: The following module(s) are unknown:
"ftfy"

Please check the spelling or version number. Also try "module spider ..."
It is also possible your cache file is out-of-date; it may help to try:
  $ module --ignore_cache load "ftfy"

Also make sure that all modulefiles written in TCL start with the string
#%Module



/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/ds/vocabs/coco_vocab.pkl
creating index...
index created!
Loading COCO Caption: n_images 113287 n_captions 566435...
loading annotations into memory...
Done (t=0.24s)
creating index...
index created!
Loading COCO Caption: n_images 1000 n_captions 5000...
loading annotations into memory...
Done (t=0.22s)
creating index...
index created!
Loading COCO Caption: n_images 5000 n_captions 25000...
Loading Flickr Caption: n_captions 148915...
Loading Flickr Caption: n_captions 5000...
Loading Flickr Caption: n_captions 5000...
Loading checkpoint from ../ckpt/BBB_woKL_Net_best.pth
Evaluating uncertainties on coco (in-distribution)
Estimating uncertainties on IOD:   0%|          | 0/313 [00:00<?, ?batch/s]Estimating uncertainties on IOD:   0%|          | 1/313 [00:03<17:43,  3.41s/batch]Estimating uncertainties on IOD:   1%|          | 2/313 [00:03<07:35,  1.46s/batch]Estimating uncertainties on IOD:   1%|          | 3/313 [00:03<04:21,  1.19batch/s]Estimating uncertainties on IOD:   1%|▏         | 4/313 [00:03<02:49,  1.82batch/s]Estimating uncertainties on IOD:   2%|▏         | 5/313 [00:03<01:59,  2.58batch/s]Estimating uncertainties on IOD:   2%|▏         | 6/313 [00:03<01:29,  3.44batch/s]Estimating uncertainties on IOD:   2%|▏         | 7/313 [00:04<01:09,  4.37batch/s]Estimating uncertainties on IOD:   3%|▎         | 8/313 [00:04<00:57,  5.31batch/s]Estimating uncertainties on IOD:   3%|▎         | 9/313 [00:04<00:49,  6.18batch/s]Estimating uncertainties on IOD:   3%|▎         | 10/313 [00:04<00:43,  6.96batch/s]Estimating uncertainties on IOD:   4%|▎         | 11/313 [00:04<00:39,  7.63batch/s]Estimating uncertainties on IOD:   4%|▍         | 12/313 [00:04<00:36,  8.17batch/s]Estimating uncertainties on IOD:   4%|▍         | 13/313 [00:04<00:35,  8.47batch/s]Estimating uncertainties on IOD:   4%|▍         | 14/313 [00:04<00:34,  8.69batch/s]Estimating uncertainties on IOD:   5%|▍         | 15/313 [00:04<00:33,  8.84batch/s]Estimating uncertainties on IOD:   5%|▌         | 16/313 [00:04<00:33,  8.98batch/s]Estimating uncertainties on IOD:   5%|▌         | 17/313 [00:05<00:32,  8.98batch/s]Estimating uncertainties on IOD:   6%|▌         | 18/313 [00:05<00:32,  9.12batch/s]Estimating uncertainties on IOD:   6%|▌         | 19/313 [00:05<00:32,  9.19batch/s]Estimating uncertainties on IOD:   6%|▋         | 20/313 [00:05<00:32,  9.14batch/s]Estimating uncertainties on IOD:   7%|▋         | 21/313 [00:05<01:07,  4.34batch/s]Estimating uncertainties on IOD:   7%|▋         | 22/313 [00:06<00:56,  5.16batch/s]Estimating uncertainties on IOD:   7%|▋         | 23/313 [00:06<00:48,  5.93batch/s]Estimating uncertainties on IOD:   8%|▊         | 24/313 [00:06<00:43,  6.63batch/s]Estimating uncertainties on IOD:   8%|▊         | 25/313 [00:06<00:39,  7.26batch/s]Estimating uncertainties on IOD:   8%|▊         | 26/313 [00:06<00:37,  7.73batch/s]Estimating uncertainties on IOD:   9%|▊         | 27/313 [00:06<00:35,  8.10batch/s]Estimating uncertainties on IOD:   9%|▉         | 28/313 [00:06<00:33,  8.40batch/s]Estimating uncertainties on IOD:   9%|▉         | 29/313 [00:06<00:33,  8.58batch/s]Estimating uncertainties on IOD:  10%|▉         | 30/313 [00:06<00:32,  8.73batch/s]Estimating uncertainties on IOD:  10%|▉         | 31/313 [00:07<00:31,  8.85batch/s]Estimating uncertainties on IOD:  10%|█         | 32/313 [00:07<00:31,  8.87batch/s]Estimating uncertainties on IOD:  11%|█         | 33/313 [00:07<00:31,  8.92batch/s]Estimating uncertainties on IOD:  11%|█         | 34/313 [00:07<00:31,  8.84batch/s]Estimating uncertainties on IOD:  11%|█         | 35/313 [00:07<00:30,  9.11batch/s]Estimating uncertainties on IOD:  12%|█▏        | 36/313 [00:07<00:30,  9.21batch/s]Estimating uncertainties on IOD:  12%|█▏        | 37/313 [00:07<00:29,  9.29batch/s]Estimating uncertainties on IOD:  12%|█▏        | 38/313 [00:07<00:29,  9.34batch/s]Estimating uncertainties on IOD:  12%|█▏        | 39/313 [00:07<00:29,  9.36batch/s]Estimating uncertainties on IOD:  13%|█▎        | 40/313 [00:07<00:29,  9.39batch/s]Estimating uncertainties on IOD:  13%|█▎        | 41/313 [00:08<00:28,  9.41batch/s]Estimating uncertainties on IOD:  13%|█▎        | 42/313 [00:08<00:28,  9.41batch/s]Estimating uncertainties on IOD:  14%|█▎        | 43/313 [00:08<00:28,  9.40batch/s]Estimating uncertainties on IOD:  14%|█▍        | 44/313 [00:08<00:28,  9.40batch/s]Estimating uncertainties on IOD:  14%|█▍        | 45/313 [00:08<00:28,  9.41batch/s]Estimating uncertainties on IOD:  15%|█▍        | 46/313 [00:08<00:28,  9.39batch/s]Estimating uncertainties on IOD:  15%|█▌        | 47/313 [00:08<00:28,  9.36batch/s]Estimating uncertainties on IOD:  15%|█▌        | 48/313 [00:08<00:28,  9.38batch/s]Estimating uncertainties on IOD:  16%|█▌        | 49/313 [00:08<00:28,  9.32batch/s]Estimating uncertainties on IOD:  16%|█▌        | 50/313 [00:09<00:28,  9.32batch/s]Estimating uncertainties on IOD:  16%|█▋        | 51/313 [00:09<00:28,  9.32batch/s]Estimating uncertainties on IOD:  17%|█▋        | 52/313 [00:09<00:27,  9.35batch/s]Estimating uncertainties on IOD:  17%|█▋        | 53/313 [00:09<00:27,  9.36batch/s]Estimating uncertainties on IOD:  17%|█▋        | 54/313 [00:09<00:27,  9.35batch/s]Estimating uncertainties on IOD:  18%|█▊        | 55/313 [00:09<00:27,  9.34batch/s]Estimating uncertainties on IOD:  18%|█▊        | 56/313 [00:09<00:27,  9.32batch/s]Estimating uncertainties on IOD:  18%|█▊        | 57/313 [00:09<00:27,  9.34batch/s]Estimating uncertainties on IOD:  19%|█▊        | 58/313 [00:09<00:27,  9.32batch/s]Estimating uncertainties on IOD:  19%|█▉        | 59/313 [00:10<00:27,  9.28batch/s]Estimating uncertainties on IOD:  19%|█▉        | 60/313 [00:10<00:27,  9.30batch/s]Estimating uncertainties on IOD:  19%|█▉        | 61/313 [00:10<00:27,  9.29batch/s]Estimating uncertainties on IOD:  20%|█▉        | 62/313 [00:10<00:27,  9.28batch/s]Estimating uncertainties on IOD:  20%|██        | 63/313 [00:10<00:26,  9.31batch/s]Estimating uncertainties on IOD:  20%|██        | 64/313 [00:10<00:26,  9.33batch/s]Estimating uncertainties on IOD:  21%|██        | 65/313 [00:10<00:26,  9.32batch/s]Estimating uncertainties on IOD:  21%|██        | 66/313 [00:10<00:26,  9.35batch/s]Estimating uncertainties on IOD:  21%|██▏       | 67/313 [00:10<00:26,  9.25batch/s]Estimating uncertainties on IOD:  21%|██▏       | 67/313 [00:11<00:40,  6.03batch/s]
Traceback (most recent call last):
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 353, in <module>
    main()
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 349, in main
    iod_ood = compare_iod_vs_ood(ckpt_path=model)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 318, in compare_iod_vs_ood
    iod_image_uncertainty, iod_text_uncertainty = estimate_uncertainty_variances(iod_valid_loader, "IOD", Net, CLIP_Net, n_fw=n_fw)
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/uncertainty_estimates.py", line 297, in estimate_uncertainty_variances
    (_, _, _, i_v), (_, _, _, t_v) = multi_fwpass_ProbVLM(
                                     ^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/utils.py", line 186, in multi_fwpass_ProbVLM
    (img_mu, img_1alpha, img_beta), (txt_mu, txt_1alpha, txt_beta) = BayesCap_Net(xfI, xfT)
                                                                     ^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/networks.py", line 141, in forward
    txt_mu, txt_1alpha, txt_beta = self.txt_BayesCap(t_features)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/src/networks.py", line 93, in forward
    x_beta = self.block_beta(x_intr)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mimer/NOBACKUP/groups/ulio_inverse/UQ/Uncertainty-Quantification-Frozen-Embeddings/alvis_code/ProbVLM/UQ_venv/lib/python3.11/site-packages/torchbnn/modules/linear.py", line 86, in forward
    weight = self.weight_mu + torch.exp(self.weight_log_sigma) * torch.randn_like(self.weight_log_sigma)
                              ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacty of 44.67 GiB of which 704.00 KiB is free. Including non-PyTorch memory, this process has 44.66 GiB memory in use. Of the allocated memory 44.29 GiB is allocated by PyTorch, and 52.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
